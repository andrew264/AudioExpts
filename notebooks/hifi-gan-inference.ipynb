{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:01.140061Z",
     "start_time": "2024-06-12T03:17:59.439329Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "\n",
    "from model import HiFiGAN, MelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8fc66c20bd7317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:01.193832Z",
     "start_time": "2024-06-12T03:18:01.140962Z"
    }
   },
   "outputs": [],
   "source": [
    "model = HiFiGAN(training=False)\n",
    "mel_spectrogram = MelSpectrogram(n_mels=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8289f1e307b556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:01.215482Z",
     "start_time": "2024-06-12T03:18:01.194774Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# cp = torch.load('../weights/generator.pth', map_location='cpu')\n",
    "# model.generator.load_state_dict(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107433efc53a3be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:01.218450Z",
     "start_time": "2024-06-12T03:18:01.216286Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_audio(mel):\n",
    "    with torch.no_grad():\n",
    "        audio = model(mel)\n",
    "    return audio.squeeze().numpy()\n",
    "\n",
    "def preprocess_audio(audio, sr=None):\n",
    "    if isinstance(audio, np.ndarray):\n",
    "        audio = torch.from_numpy(audio)\n",
    "    if audio.dim() == 1:\n",
    "        audio = audio.unsqueeze(0)\n",
    "    mel = mel_spectrogram(audio.float(), sr=sr)\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a985f6e2ef771f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:07.654633Z",
     "start_time": "2024-06-12T03:18:01.218952Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\", trust_remote_code=True)\n",
    "sample = ds[0][\"audio\"]\n",
    "sample_rate, waveform = sample['sampling_rate'], sample['array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f3c499ef6bdca59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:07.922792Z",
     "start_time": "2024-06-12T03:18:07.655540Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, hifigan, filter_length=1024, hop_size=512, win_length=1024):\n",
    "        super(Denoiser, self).__init__()\n",
    "        self.filter_length = filter_length\n",
    "        self.hop_size = hop_size\n",
    "        self.win_length = win_length\n",
    "        self.window = torch.hann_window(self.win_length)\n",
    "        self.register_buffer('bias_spec', self.compute_bias_spec(hifigan), persistent=False)\n",
    "        \n",
    "    def compute_bias_spec(self, hifigan):\n",
    "        with torch.no_grad():\n",
    "            mel_input = torch.zeros(1, 128, 100)\n",
    "            bias_audio = hifigan(mel_input).float().squeeze()\n",
    "            bias_spec = torch.stft(bias_audio, self.filter_length, self.hop_size, self.win_length,\n",
    "                                   window=self.window, return_complex=True)[:, 0][:, None]\n",
    "        return bias_spec\n",
    "\n",
    "    def forward(self, audio, strength=0.05):\n",
    "        if isinstance(audio, np.ndarray):\n",
    "            audio = torch.from_numpy(audio)\n",
    "        if audio.dim() == 1:\n",
    "            audio = audio.unsqueeze(0)\n",
    "        \n",
    "        audio_stft = torch.stft(audio, self.filter_length, self.hop_size, self.win_length,\n",
    "                                window=self.window, return_complex=True)\n",
    "        \n",
    "        audio_spec_denoised = audio_stft - self.bias_spec * strength\n",
    "        audio_denoised = torch.istft(audio_spec_denoised, self.filter_length, self.hop_size,\n",
    "                                     self.win_length, window=self.window, return_complex=False)\n",
    "        return audio_denoised\n",
    "\n",
    "d = Denoiser(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de65340f3a72fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:07.955153Z",
     "start_time": "2024-06-12T03:18:07.923576Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(waveform, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6480d29e226131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:07.959936Z",
     "start_time": "2024-06-12T03:18:07.956153Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.from_numpy(waveform).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3104793b59bf0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:08.906264Z",
     "start_time": "2024-06-12T03:18:07.960443Z"
    }
   },
   "outputs": [],
   "source": [
    "full_audio = []\n",
    "for i in range(0, len(waveform), 16000):\n",
    "    audio = generate_audio(preprocess_audio(waveform[i:i+16000]))\n",
    "    full_audio.extend(audio)\n",
    "full_audio = np.array(full_audio)\n",
    "de_noised_audio = d(full_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd13e4b46d1784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:08.912082Z",
     "start_time": "2024-06-12T03:18:08.907397Z"
    }
   },
   "outputs": [],
   "source": [
    "ipd.Audio(full_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ed35bba610687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:08.922058Z",
     "start_time": "2024-06-12T03:18:08.912823Z"
    }
   },
   "outputs": [],
   "source": [
    "ipd.Audio(de_noised_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde406985ccdba05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:08.977067Z",
     "start_time": "2024-06-12T03:18:08.922679Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load(\"../data/1170331873109626940.ogg\")\n",
    "waveform = waveform[0]\n",
    "ipd.Audio(waveform, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2324f2e1caa38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:10.825154Z",
     "start_time": "2024-06-12T03:18:08.977777Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform = torch.nn.functional.pad(waveform, (0, 16000 - waveform.shape[0] % 16000))\n",
    "waveform = waveform.reshape(-1, 16000)\n",
    "preprocessed = preprocess_audio(waveform, sr=sample_rate)\n",
    "generated = generate_audio(preprocessed).reshape(-1)\n",
    "ipd.Audio(generated, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393ef5ef7736b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T03:18:10.836607Z",
     "start_time": "2024-06-12T03:18:10.825993Z"
    }
   },
   "outputs": [],
   "source": [
    "denoised = d(generated)\n",
    "ipd.Audio(denoised, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
